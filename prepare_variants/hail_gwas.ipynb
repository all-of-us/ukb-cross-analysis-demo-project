{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Perform the genome-wide association study"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this notebook, we use Hail to perform a genome-wide association study on the merged variants of the AoU and UKB participants."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "import hail as hl\n",
    "import os\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define constants"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class='alert alert-block alert-info'>\n",
    "    <b>Note:</b> These matrix tables were created via notebook <kbd>merge_variants.ipynb</kbd>.\n",
    "</div>\n",
    "\n",
    "```\n",
    "1500 gs://fc-secure-fd6786bf-6c28-4f33-ac30-3860fbeee5bb/data/merged/20210712/merged-filtered-chr1.mt\n",
    "1000 gs://fc-secure-fd6786bf-6c28-4f33-ac30-3860fbeee5bb/data/merged/20210712/merged-filtered-chr2.mt\n",
    "879 gs://fc-secure-fd6786bf-6c28-4f33-ac30-3860fbeee5bb/data/merged/20210622/merged-filtered-chr3.mt\n",
    "1152 gs://fc-secure-fd6786bf-6c28-4f33-ac30-3860fbeee5bb/data/merged/20210624/merged-filtered-chr4.mt\n",
    "1284 gs://fc-secure-fd6786bf-6c28-4f33-ac30-3860fbeee5bb/data/merged/20210624/merged-filtered-chr5.mt\n",
    "14286 gs://fc-secure-fd6786bf-6c28-4f33-ac30-3860fbeee5bb/data/merged/20210628/merged-filtered-chr6_chr7_chr8_chr9_chr10_chr11_chr12_chr13_chr14_chr15_chr16_chr17_chr18_chr19_chr20.mt\n",
    "1775 gs://fc-secure-fd6786bf-6c28-4f33-ac30-3860fbeee5bb/data/merged/20210603/merged-filtered-chr21.mt\n",
    "1812 gs://fc-secure-fd6786bf-6c28-4f33-ac30-3860fbeee5bb/data/merged/20210624/merged-filtered-chr22.mt\n",
    "576 gs://fc-secure-fd6786bf-6c28-4f33-ac30-3860fbeee5bb/data/merged/20210628/merged-filtered-chrX.mt\n",
    "9 gs://fc-secure-fd6786bf-6c28-4f33-ac30-3860fbeee5bb/data/merged/20210624/merged-filtered-chrY.mt\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MERGED_MT = [\n",
    "    'gs://fc-secure-fd6786bf-6c28-4f33-ac30-3860fbeee5bb/data/merged/20210712/merged-filtered-chr1.mt',\n",
    "    'gs://fc-secure-fd6786bf-6c28-4f33-ac30-3860fbeee5bb/data/merged/20210712/merged-filtered-chr2.mt',\n",
    "    'gs://fc-secure-fd6786bf-6c28-4f33-ac30-3860fbeee5bb/data/merged/20210622/merged-filtered-chr3.mt',\n",
    "    'gs://fc-secure-fd6786bf-6c28-4f33-ac30-3860fbeee5bb/data/merged/20210624/merged-filtered-chr4.mt',\n",
    "    'gs://fc-secure-fd6786bf-6c28-4f33-ac30-3860fbeee5bb/data/merged/20210624/merged-filtered-chr5.mt',\n",
    "    'gs://fc-secure-fd6786bf-6c28-4f33-ac30-3860fbeee5bb/data/merged/20210628/merged-filtered-chr6_chr7_chr8_chr9_chr10_chr11_chr12_chr13_chr14_chr15_chr16_chr17_chr18_chr19_chr20.mt',\n",
    "    'gs://fc-secure-fd6786bf-6c28-4f33-ac30-3860fbeee5bb/data/merged/20210603/merged-filtered-chr21.mt',\n",
    "    'gs://fc-secure-fd6786bf-6c28-4f33-ac30-3860fbeee5bb/data/merged/20210624/merged-filtered-chr22.mt',\n",
    "    'gs://fc-secure-fd6786bf-6c28-4f33-ac30-3860fbeee5bb/data/merged/20210628/merged-filtered-chrX.mt',\n",
    "    'gs://fc-secure-fd6786bf-6c28-4f33-ac30-3860fbeee5bb/data/merged/20210624/merged-filtered-chrY.mt'\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class='alert alert-block alert-info'>\n",
    "The variant quality control metrics were computed via <a href='https://hail.is/docs/0.2/methods/genetics.html#hail.methods.variant_qc'>hail.methods.variant_qc</a> in notebook <kbd>compute_variant_qcs.ipynb</kbd>.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "VARIANT_QCS_TAB = 'gs://fc-secure-fd6786bf-6c28-4f33-ac30-3860fbeee5bb/data/merged/20210712/variant_qcs.tab'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class='alert alert-block alert-info'>\n",
    "The phenotypes and covariates were wrangled via notebooks <kbd>AOU_UKB_phenotypes.ipynb</kbd> and <kbd>compute_pcs.ipynb</kbd>.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PHENOTYPES_CSV = 'gs://fc-secure-fd6786bf-6c28-4f33-ac30-3860fbeee5bb/data/FULL_Data_Iteration1_ForGWAS.csv'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class='alert alert-block alert-info'>\n",
    "We have several lipids phenotypes for which we will perform a GWAS. But we compute them one at a time, controlled by the constant <kbd>TARGET_PHENOTYPE</kbd>.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TARGET_PHENOTYPE = 'LDL_norm'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class='alert alert-block alert-success'>\n",
    "    Limit to a small region for testing purposes. Limit to the <b>autosome</b> for the full analysis.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "INTERVALS_TO_EXAMINE = [f'chr{chrom}' for chrom in range(21, 22)]\n",
    "INTERVALS_TO_EXAMINE_NAME = '_'.join(INTERVALS_TO_EXAMINE).replace(':', 'range')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "RESULT_BUCKET = os.getenv('WORKSPACE_BUCKET')\n",
    "DATESTAMP = time.strftime('%Y%m%d')\n",
    "TIMESTAMP = time.strftime('%Y%m%d_%H%M%S')\n",
    "WORK_DIR = !pwd\n",
    "\n",
    "# Outputs\n",
    "GWAS_TAB = f'{os.getenv(\"WORKSPACE_BUCKET\")}/data/merged/{DATESTAMP}/gwas-{TARGET_PHENOTYPE}-{INTERVALS_TO_EXAMINE_NAME}.tab'\n",
    "HAIL_LOG = f'{WORK_DIR[0]}/hail-gwas-{TIMESTAMP}.log'\n",
    "HAIL_LOG_DIR_FOR_PROVENANCE = f'{os.getenv(\"WORKSPACE_BUCKET\")}/hail-logs/{DATESTAMP}/'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Check access"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for mt in MERGED_MT:\n",
    "    !gsutil ls {mt}\n",
    "    print('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!gsutil ls {VARIANT_QCS_TAB}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!gsutil ls {PHENOTYPES_CSV}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Start Hail "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# See also https://towardsdatascience.com/fetch-failed-exception-in-apache-spark-decrypting-the-most-common-causes-b8dff21075c\n",
    "# See https://spark.apache.org/docs/2.4.7/configuration.html\n",
    "\n",
    "EXTRA_SPARK_CONFIG = {\n",
    "    # If set to 'true', performs speculative execution of tasks. This means if one or more tasks are running\n",
    "    # slowly in a stage, they will be re-launched.\n",
    "    'spark.speculation': 'true', # Default is false.\n",
    "    \n",
    "    # Fraction of tasks which must be complete before speculation is enabled for a particular stage.\n",
    "    'spark.speculation.quantile': '0.95', # Default is 0.75\n",
    "\n",
    "    # Default timeout for all network interactions. This config will be used in place of \n",
    "    # spark.core.connection.ack.wait.timeout, spark.storage.blockManagerSlaveTimeoutMs, \n",
    "    # spark.shuffle.io.connectionTimeout, spark.rpc.askTimeout or spark.rpc.lookupTimeout if they are not configured.\n",
    "    'spark.network.timeout': '180s', # Default is 120s\n",
    "        \n",
    "    # (Netty only) Fetches that fail due to IO-related exceptions are automatically retried if this is set to a\n",
    "    # non-zero value. This retry logic helps stabilize large shuffles in the face of long GC pauses or transient\n",
    "    # network connectivity issues.\n",
    "    'spark.shuffle.io.maxRetries': '10',  # Default is 3\n",
    "    \n",
    "    # (Netty only) How long to wait between retries of fetches. The maximum delay caused by retrying is 15 seconds\n",
    "    # by default, calculated as maxRetries * retryWait.\n",
    "    'spark.shuffle.io.retryWait': '15s',  # Default is 5s\n",
    "    \n",
    "    # Number of failures of any particular task before giving up on the job. The total number of failures spread\n",
    "    # across different tasks will not cause the job to fail; a particular task has to fail this number of attempts.\n",
    "    # Should be greater than or equal to 1. Number of allowed retries = this value - 1.\n",
    "    'spark.task.maxFailures': '10', # Default is 4.\n",
    "\n",
    "    # Number of consecutive stage attempts allowed before a stage is aborted.\n",
    "    'spark.stage.maxConsecutiveAttempts': '10' # Default is 4.\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hl.init(spark_conf=EXTRA_SPARK_CONFIG,\n",
    "        min_block_size=50,\n",
    "        default_reference='GRCh38',\n",
    "        log=HAIL_LOG)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check the configuration."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sc = hl.spark_context()\n",
    "config = sc._conf.getAll()\n",
    "config.sort()\n",
    "config"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load input data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read the matrix table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(0, len(MERGED_MT)):\n",
    "    mt = hl.read_matrix_table(MERGED_MT[i])\n",
    "    print(f'{mt.n_partitions()} {MERGED_MT[i]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged = hl.read_matrix_table(MERGED_MT[0])\n",
    "\n",
    "for i in range(1, len(MERGED_MT)):\n",
    "    merged = merged.union_rows(hl.read_matrix_table(MERGED_MT[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TEMPORARY: fix the sample id key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged = merged.annotate_cols(cohort_key = merged.s + '_' + merged.cohort)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged = merged.key_cols_by(merged.cohort_key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged.cols().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Filter to our intervals of interest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if len(INTERVALS_TO_EXAMINE) > 0:\n",
    "    merged = hl.filter_intervals(\n",
    "        merged,\n",
    "        [hl.parse_locus_interval(x) for x in INTERVALS_TO_EXAMINE],\n",
    "        keep=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_count = merged.count()\n",
    "\n",
    "merged_count"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read the variant QCs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_variant_qc = hl.read_table(VARIANT_QCS_TAB)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_variant_qc.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_variant_qc.count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read the phenotypes and covariates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "phenotypes = (hl.import_table(PHENOTYPES_CSV,\n",
    "                              impute=True,\n",
    "                              delimiter=',',\n",
    "                              missing='',\n",
    "                              types={'s':hl.tstr})\n",
    "              .rename({'\\ufeffid': 's', 'gender': 'sex'}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "phenotypes.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "phenotypes.count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TEMPORARY: fix the sample id key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "phenotypes = phenotypes.key_by(phenotypes.s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "id_map = hl.import_table('gs://uk-biobank-sek-data-us-east1/sample-info/bridge_7089_31063.tsv',\n",
    "                         impute=True).key_by('eid_7089')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "phenotypes = phenotypes.join(id_map, how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "phenotypes.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "phenotypes = phenotypes.annotate(\n",
    "    cohort_key = hl.if_else(\n",
    "        hl.is_defined(phenotypes.eid_31063),\n",
    "        hl.str(phenotypes.eid_31063) + '_' + phenotypes.CohortName.lower(),\n",
    "        hl.str(phenotypes.s) + '_' + phenotypes.CohortName.lower()\n",
    "    ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "phenotypes = phenotypes.key_by(phenotypes.cohort_key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "phenotypes.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create indicator variables for the categorical variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "phenotypes.aggregate(hl.agg.counter(phenotypes.CohortName))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "phenotypes = phenotypes.annotate(\n",
    "    is_aou_cohort = (hl.case()\n",
    "                     .when(phenotypes.CohortName == 'AOU', 1)\n",
    "                     .when(phenotypes.CohortName == 'UKB', 0)\n",
    "                     .or_missing()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "phenotypes.aggregate(hl.agg.counter(phenotypes.is_aou_cohort))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "phenotypes.aggregate(hl.agg.counter(phenotypes.sex))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "phenotypes = phenotypes.annotate(\n",
    "    is_male = (hl.case()\n",
    "               # https://biobank.ndph.ox.ac.uk/showcase/coding.cgi?id=9\n",
    "               .when(phenotypes.sex == '1', 1)\n",
    "               .when(phenotypes.sex == '0', 0)\n",
    "               .when(phenotypes.sex == 'Male', 1)\n",
    "               .when(phenotypes.sex == 'Female', 0)\n",
    "               .or_missing()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "phenotypes.aggregate(hl.agg.counter(phenotypes.is_male))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#phenotypes.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "phenotypes.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_samples_expected = phenotypes.count()\n",
    "\n",
    "num_samples_expected"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TEMPORARY: write out fixed phenotypes for use with regenie"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "FIXED_PHENOTYPES_TSV = f'{os.getenv(\"WORKSPACE_BUCKET\")}/data/merged/{DATESTAMP}/phenotypes.tsv'\n",
    "\n",
    "phenotypes.export(FIXED_PHENOTYPES_TSV)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TODO AoU WGS sample QC results?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TODO UKB WES sample QC results?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Annotate and filter to high quality input data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Filter variants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged = merged.annotate_rows(\n",
    "    callRate = combined_variant_qc[merged.row_key].variant_qc.call_rate)\n",
    "\n",
    "merged = merged.annotate_rows(\n",
    "    AF = combined_variant_qc[merged.row_key].variant_qc.AF)\n",
    "\n",
    "merged = merged.annotate_rows(\n",
    "    AC = combined_variant_qc[merged.row_key].variant_qc.AC)\n",
    "\n",
    "merged = merged.annotate_rows(\n",
    "    pHWE = combined_variant_qc[merged.row_key].variant_qc.p_value_hwe)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Per Margaret: include high-quality independent autosomal variants subset' with \n",
    "* MAF > 0.1%, missingness < 1%, \n",
    "* HWE P > 10-6 and two rounds of pruning using --indep-pairwise 200 100 0.1 and --indep-pairwise 200 100 0.05 in PLINK4. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO(deflaux) reconcile these cutoffs from the albuminuria GWAS with Margaret's recommendation\n",
    "merged = merged.filter_rows(merged.pHWE > 1e-20, keep=True)       # HWE P > 10-20 ---> less strict\n",
    "merged = merged.filter_rows(merged.callRate > 0.95, keep=True)    # missingness < 5% ---> less strict\n",
    "merged = merged.filter_rows(hl.min(merged.AF) > 0.001, keep=True) # MAF > 0.1%\n",
    "merged = merged.filter_rows(hl.min(merged.AF) < 0.999, keep=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Filter samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged = merged.filter_cols(hl.is_defined(phenotypes[merged.col_key]), keep=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged = merged.annotate_cols(**phenotypes[merged.col_key])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Check the result of filtering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start = datetime.now()\n",
    "print(start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_merged_count = merged.count()\n",
    "\n",
    "filtered_merged_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "end = datetime.now()\n",
    "print(end)\n",
    "print(end - start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if num_samples_expected == filtered_merged_count[1]:\n",
    "    print(f'Number of samples: {filtered_merged_count[1]}')\n",
    "else:\n",
    "    print(f'''\n",
    "        Our data does not have the same number of samples as those from the\n",
    "        derived phenotype.\n",
    "            Expected: {num_samples_expected}\n",
    "            Actual: {filtered_merged_count[1]}\n",
    "        ''')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'''\n",
    "    Number of variants prior to filtering: {merged_count[0]}\n",
    "    Number of variants after filtering: {filtered_merged_count[0]}\n",
    "    Number of variants removed by filtering: {merged_count[0] - filtered_merged_count[0]}\n",
    "    ''')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Perform the GWAS "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged = merged.rename({TARGET_PHENOTYPE: 'target_phenotype'})\n",
    "\n",
    "TARGET_PHENOTYPE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "covar_cols = [1.0, merged.is_male, merged.age, merged.age2, merged.is_aou_cohort,\n",
    "              merged.pc1, merged.pc2, merged.pc3, merged.pc4, merged.pc5,\n",
    "              merged.pc6, merged.pc7, merged.pc8, merged.pc9, merged.pc10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_linassoc = hl.linear_regression_rows(\n",
    "    y=merged.target_phenotype,\n",
    "    x=merged.GT.n_alt_alleles(),\n",
    "    covariates=covar_cols,\n",
    "    pass_through=[\n",
    "        'callRate',\n",
    "        'AF',\n",
    "        'AC',\n",
    "        'pHWE']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_linassoc.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start = datetime.now()\n",
    "print(start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Starting linear regression:')\n",
    "merged_linassoc.write(GWAS_TAB)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "end = datetime.now()\n",
    "print(end)\n",
    "print(end - start)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Provenance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Copy the Hail log to the workspace bucket so that we can retain it.\n",
    "!gzip --keep {HAIL_LOG}\n",
    "!gsutil cp {HAIL_LOG}.gz {HAIL_LOG_DIR_FOR_PROVENANCE}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(datetime.now())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip3 freeze"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "405px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
