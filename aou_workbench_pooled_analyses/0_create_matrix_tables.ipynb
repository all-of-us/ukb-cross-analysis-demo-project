{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create matrix tables "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this notebook, we prepare matrix tables for use in analysis."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "import hail as hl\n",
    "import os\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Retrieve exome region file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!wget -nd biobank.ndph.ox.ac.uk/ukb/ukb/auxdata/xgen_plus_spikein.GRCh38.bed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!gsutil cp xgen_plus_spikein.GRCh38.bed ${WORKSPACE_BUCKET}/data/ukb/exomes/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "AOU_VCFS = 'gs://fc-aou-preprod-datasets-controlled/5/wgs/vcf/merged/alpha2/*.vcf.gz'\n",
    "UKB_VCFS = 'gs://fc-7130e767-a885-4678-95ed-7c966c79e2d0/200K/pvcf/ukb23156_*.vcf.gz'\n",
    "EXOME_REGIONS = f'{os.getenv(\"WORKSPACE_BUCKET\")}/data/ukb/exomes/xgen_plus_spikein.GRCh38.bed'\n",
    "\n",
    "INPUT_VCFS = AOU_VCFS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "RESULT_BUCKET = os.getenv(\"WORKSPACE_BUCKET\")\n",
    "DATESTAMP = time.strftime('%Y%m%d')\n",
    "TIMESTAMP = time.strftime('%Y%m%d_%H%M%S')\n",
    "WORK_DIR = !pwd\n",
    "\n",
    "# Output files\n",
    "OUTPUT_MT = f'{os.getenv(\"WORKSPACE_BUCKET\")}/data/aou/alpha2/cohort.mt'\n",
    "HAIL_LOG = f'{WORK_DIR[0]}/hail-make-mt-{TIMESTAMP}.log'\n",
    "HAIL_LOG_DIR_FOR_PROVENANCE = f'{os.getenv(\"WORKSPACE_BUCKET\")}/hail-logs/{DATESTAMP}/'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Check access"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!gsutil ls {AOU_VCFS} | head"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!gsutil ls {UKB_VCFS} | head"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Start Hail "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# See also https://towardsdatascience.com/fetch-failed-exception-in-apache-spark-decrypting-the-most-common-causes-b8dff21075c\n",
    "# See https://spark.apache.org/docs/2.4.7/configuration.html\n",
    "\n",
    "EXTRA_SPARK_CONFIG = {\n",
    "    # If set to \"true\", performs speculative execution of tasks. This means if one or more tasks are running\n",
    "    # slowly in a stage, they will be re-launched.\n",
    "    'spark.speculation': 'true', # Default is false.\n",
    "    \n",
    "    # Fraction of tasks which must be complete before speculation is enabled for a particular stage.\n",
    "    'spark.speculation.quantile': '0.95', # Default is 0.75\n",
    "\n",
    "    # Default timeout for all network interactions. This config will be used in place of \n",
    "    # spark.core.connection.ack.wait.timeout, spark.storage.blockManagerSlaveTimeoutMs, \n",
    "    # spark.shuffle.io.connectionTimeout, spark.rpc.askTimeout or spark.rpc.lookupTimeout if they are not configured.\n",
    "    'spark.network.timeout': '180s', # Default is 120s\n",
    "        \n",
    "    # (Netty only) Fetches that fail due to IO-related exceptions are automatically retried if this is set to a\n",
    "    # non-zero value. This retry logic helps stabilize large shuffles in the face of long GC pauses or transient\n",
    "    # network connectivity issues.\n",
    "    'spark.shuffle.io.maxRetries': '10',  # Default is 3\n",
    "    \n",
    "    # (Netty only) How long to wait between retries of fetches. The maximum delay caused by retrying is 15 seconds\n",
    "    # by default, calculated as maxRetries * retryWait.\n",
    "    'spark.shuffle.io.retryWait': '15s',  # Default is 5s\n",
    "    \n",
    "    # Number of failures of any particular task before giving up on the job. The total number of failures spread\n",
    "    # across different tasks will not cause the job to fail; a particular task has to fail this number of attempts.\n",
    "    # Should be greater than or equal to 1. Number of allowed retries = this value - 1.\n",
    "    'spark.task.maxFailures': '10', # Default is 4.\n",
    "\n",
    "    # Number of consecutive stage attempts allowed before a stage is aborted.\n",
    "    'spark.stage.maxConsecutiveAttempts': '10' # Default is 4.\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hl.init(spark_conf=EXTRA_SPARK_CONFIG,\n",
    "        min_block_size=50,\n",
    "        default_reference='GRCh38',\n",
    "        log=HAIL_LOG)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check the configuration."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sc = hl.spark_context()\n",
    "config = sc._conf.getAll()\n",
    "config.sort()\n",
    "config"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load exome capture regions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ukb_exome_capture_regions = hl.import_bed(EXOME_REGIONS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ukb_exome_capture_regions.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ukb_exome_capture_regions.show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create matrix table from VCFs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mt = hl.import_vcf(INPUT_VCFS,\n",
    "                   array_elements_required=False,\n",
    "                   force_bgz=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mt.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mt = mt.filter_rows(\n",
    "    hl.is_defined(ukb_exome_capture_regions[mt.locus]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start = datetime.now()\n",
    "print(start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mt.write(OUTPUT_MT, overwrite=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "end = datetime.now()\n",
    "print(end)\n",
    "print(end - start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!gsutil ls {OUTPUT_MT}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Provenance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Copy the Hail log to the workspace bucket so that we can retain it.\n",
    "!gzip --keep {HAIL_LOG}\n",
    "!gsutil cp {HAIL_LOG}.gz {HAIL_LOG_DIR_FOR_PROVENANCE}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(datetime.now())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip3 freeze"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "258px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
